{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Занятие №1. Основные понятия и шаги при работе с методами искусственного интеллекта.\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev\n",
    "\n",
    "#### План занятия.\n",
    "1. Основные понятия в области ИИ.\n",
    "2. Построение модели и процедура оптимизации на простом примере.\n",
    "3. (Почти) реальная задача по распознаванию изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные понятия\n",
    "\n",
    "__Объект__ – атомарная сущность в некоторой задаче. Как правило, для объекта необходимо предсказать значение целевой переменной, принадлежность к некоторой группе объектов или же другое свойство.\n",
    "\n",
    "__Признак__ – величина, описывающая одно из свойств объекта. Например, число (рост), категория (цвет глаз). К признаковому описанию объекта могут быть отнесены и более сложные структуры, например, изображение или запись голоса.\n",
    "\n",
    "__Задача обучения с учителем, supervised learning problem__ – задача, в которой необходимо предсказать значение __целевой переменной (ответа)__ на новом (ранее не наблюдаемом) объекте. __Для некоторого множества объектов эти значения известны (например, получены с помощью экспертной разметки).__\n",
    "\n",
    "__Задача регрессии__ – задача обучения с учителем, где целевая переменная является континуальным числом (т.е. принимает континуальное число значений). Например, предсказание ожидаемой зарплаты на основе резюме соискателя. Или же предсказание возраста пользователя интернета на основе его поведения в интернете.\n",
    "\n",
    "__Задача классификации__ – задача обучения с учителем, где целевая переменная является меткой класса (т.е. может принимать конечное число значений). Например, определение эмоциональной окраски сообщения (позитивная или негативная), или же определение социальной группы, к которой принадлежит клиент банка на основе его трат. Часто разделяют бинарную классификацию (где рассматривается всего два класса, например фрод/не фрод) и мультиклассовую классификацию (где классов может быть конечное число, например пять социальных групп).\n",
    "\n",
    "__Модель__ (в обучении с учителем) – функция или правило, позволяющая предсказать ответ для любого объекта подходящей структуры (т.е. описываемого теми же признаками, с которыми работает модель). Формально, отображение из пространства объектов в пространство ответов.\n",
    "\n",
    "__Набор данных, выборка, датасет__  – множество пар объект-ответ (в обучении с учителем), которое используется при настройке параметров (обучении) модели. В обучении без учителя просто множество объектов.\n",
    "\n",
    "__Задача обучения без учителя, unsupervised learning__ – задача, в которой __нет целевой переменной__ и, как правило, необходимо найти некоторую внутреннюю структуру данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow==8.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка версий библиотек\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f'Python version: {sys.version}\\n')\n",
    "print(f'torch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка небольшого файла для третьей части практического занятия\n",
    "!wget https://raw.githubusercontent.com/neychev/small_DL_repo/master/PyTorch_seminars/1._Intro_to_DL/input.html -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для построения графиков на темном фоне раскомментируйте следующую строчку\n",
    "# plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простая модель и градиентная оптимизация\n",
    "\n",
    "Методы искусственного интеллекта опираются на многие результаты человеческой мысли. Одним из столпов существующих достижений является оптимизация: поиск оптимальной (наилучшей) струкруты модели, ее параметров, правил, по которым она работает и др.\n",
    "\n",
    "В большинстве значимых решений на основе искусственного интеллекта используются [__градиентные методы оптимизации__](https://ru.wikipedia.org/wiki/Градиентные_методы). Т.е. происходит оптимизация некоторого функционала (например, метрики), который зависит от исходных данных и модели некоторым дифференцируемым образом.\n",
    "\n",
    "Начнем с простой иллюстрации градиентной оптимизации. Похожие механизмы работают при обучении (т.е. настройке) очень сложных моделей, например систем автопилота в автомобилях.\n",
    "\n",
    "Для примера воспользуемся классическим набором даных о стоимости жилья в Бостоне. Его описание доступно ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать только последний признак (`LSTAT – % lower status of the population`) для более наглядной визуализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(boston.data[:, -1], boston.target)\n",
    "plt.xlabel('LSTAT, % lower status of the population')\n",
    "plt.ylabel('Median value of owner-occupied homes in $1000\\'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование данных в формат torch.tensor\n",
    "x = torch.tensor(boston.data[:,-1] / 10, dtype=torch.float32)\n",
    "y = torch.tensor(boston.target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем предсказать значение целевой переменной (стоимости жилья) на основе одного признака (LSTAT). Для простоты воспользуемся линейной моделью. В таком случае `w` и `b` будут параметрами (весами) модели (и будут определять наклон прямой и ее сдвиг соответственно). Качество нашей модели будем оценивать, например, при помощи среднеквадратичной ошибки.\n",
    "\n",
    "Код далее демонстрирует простейшую линейную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация параметров модели\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# Сама линейная модель\n",
    "y_pred = w * x + b\n",
    "\n",
    "# Среднеквадратичная ошибка\n",
    "loss = torch.mean( (y_pred - y)**2 )\n",
    "\n",
    "# Подсчет градиента для параметров модели\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на градиенты параметров модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dL/dw = {}\\n\".format(w.grad))\n",
    "print(\"dL/db = {}\\n\".format(b.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти величины указывают, насколько стоит изменить значения параметров, чтобы ошибка стала меньше.\n",
    "\n",
    "Теперь воспользуемся градиентной оптимизацией для нахождения (суб)-оптимального значения параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    y_pred = w * x + b\n",
    "    loss = torch.mean( (y_pred - y)**2 )\n",
    "    loss.backward()\n",
    "\n",
    "    w.data -= 0.05 * w.grad.data\n",
    "    b.data -= 0.05 * b.grad.data\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "    \n",
    "    # the rest of code is just bells and whistles\n",
    "    if (i+1)%5==0:\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy(), label='real value')\n",
    "        plt.scatter(x.data.numpy(), y_pred.data.numpy(), color='orange', linewidth=5, label='predicted value')\n",
    "        plt.grid()\n",
    "        plt.xlabel('LSTAT, % lower status of the population')\n",
    "        plt.ylabel('Median value of owner-occupied homes in $1000\\'s')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.data.numpy())\n",
    "        if loss.data.numpy() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, целевая переменная зависит от исходного признака нелинейно. Использование нелинейных преобразований может быть полезным. Но, при этом сама процедура оптимизации не изменяется. Только что мы продемонстрировали это при использовании некоторой нелинейной функции для преобразования признака (например, `torch.log`). Главное, чтобы эта функция была дифференцируемой и не сломала механизм градиентной оптимизации.\n",
    "\n",
    "Подобным образом происходит настройка параметров (миллионов и даже [сотен миллиардов](https://venturebeat.com/2020/05/29/openai-debuts-gigantic-gpt-3-language-model-with-175-billion-parameters/)) параметров и в более сложных моделях, например, глубоких нейронных сетях. На пример использования нейронной сети и посмотрим далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Почти) реальная задача\n",
    "Теперь же обратимся к более сложной задаче. Например, к распознаванию рукописных цифр, и воспользуемся набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). Классификация MNIST – своеобразный \"Hello world\" в мире компьютерного зрения и машинного обучения в целом, и является классическим примером. Конечно, в настоящий момент подобный набор данных выглядит \"игрушечным\" (и в научной среде уже не раз упоминалась его излишне простая структура), но своей наглядности и истории он от этого не теряет.\n",
    "\n",
    "Загрузка и предобработка данных практически полностью сделана за нас. Набор данных состоит из $60000$ черно-белых изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HiRxvvZ0CJ64"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8n7N56E0CJ67",
    "outputId": "ce5e5b95-9192-44f5-e5a9-0a3d10f2f090"
   },
   "outputs": [],
   "source": [
    "print(f'train dataset size: {len(train_mnist_data)}\\ntest dataset size: {len(test_mnist_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CvH5g-ldCJ67"
   },
   "source": [
    "В обучающей выборке `train_mnist_data` содержатся $60000$ примеров, на которые мы будем настраивать параметры нашей модели. Тестовая выборка `test_mnist_data` (содержит $10000$ примеров) будет использоваться для оценки качества итоговой модели.\n",
    "\n",
    "Рассмотрим данные внимательно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train image shape: {train_mnist_data[0][0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjoIibDTCJ6_",
    "outputId": "d149eb72-5059-4940-9a74-a8c84701ddf0"
   },
   "outputs": [],
   "source": [
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По факту, каждое черно-белое изображение можно представить в виде матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEY6x2WACJ7C",
    "outputId": "b251efa9-fb08-49c6-bf07-0b9a93c70411"
   },
   "outputs": [],
   "source": [
    "print(f'test image shape: {test_mnist_data[0][0].shape}\\ntest dataset size: {len(test_mnist_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения данной задачи классификации воспользуемся простой нейронной сетью, реализованной с помощью PyTorch. Не будем погружаться в тонкости реализации на данный момент. Если хочется узнать больше прямо сейчас, то всегда можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  Пример документации доступен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.Module.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейшую нейронную сеть из одного слоя (по факту, это просто логистическая регрессия). На вход будем подавать 784 признака, т.е. значение каждого пикселя изображения. Предсказывать будем ненормированные вероятности для каждого класса (т.е. 10 чисел)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем класс модели\n",
    "model = nn.Sequential()\n",
    "\n",
    "# Добавляем первый слой, отображающий 784 признака (28*28 пикселей) в 10 целевых значений\n",
    "model.add_module('l1', nn.Linear(784, 128))\n",
    "model.add_module('relu', nn.ReLU())\n",
    "model.add_module('l2', nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге у нашей модели $7850$ параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weight shapes:\", [w.shape for w in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy data with 32 (`batch_size`) samples and 784 features\n",
    "x = random_batch[0].reshape(-1, 784)\n",
    "y = random_batch[1]\n",
    "\n",
    "# compute outputs given inputs, both are variables\n",
    "y_predicted = model(x)\n",
    "\n",
    "plt.pcolormesh(F.softmax(y_predicted[:4], dim=-1).detach()) # display what we've got\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции ошибки воспользуемся перекрестной энтропией (или кроссэнтропией, как ее принято называть). Она оценивает, насколько предсказанные вероятности принадлежности к тому или иному классу соответствуют истинным (100% верному классу, 0% всем остальным)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "loss = loss_function(y_predicted, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение функции ошибки получилось следующим. Нельзя сказать, что оно слишком информативно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В широко используемых фреймворках многие операции производятся \"под капотом\". Например, шаг градиентного спуска (в отличие от кода, который мы использовали выше с предскзаанием цен на недвижимость в Бостоне)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "# Оценка градиента\n",
    "loss.backward()   \n",
    "# Шаг градиентного спуска\n",
    "opt.step()           \n",
    "# Очистка буфера градиентов ()\n",
    "opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна эпоха обучения включает в себя количество шагов, необходимых для покрытия всего датасета (примерно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "history = []\n",
    "plot_history = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for _i, batch in enumerate(train_data_loader):\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        # Предсказание модели (логиты, которые можно преобразовать в вероятности)\n",
    "        y_predicted = model(x_batch.reshape(-1, 784))\n",
    "\n",
    "        # Вычисление значения функции потерь\n",
    "        loss = loss_function(y_predicted, y_batch)\n",
    "\n",
    "        # Вычисление градиентов\n",
    "        loss.backward()\n",
    "\n",
    "        # Шаг оптимизации\n",
    "        opt.step()\n",
    "\n",
    "        # Очистка буфера градиентов\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss.item())\n",
    "\n",
    "        if (_i+50)%100==0:\n",
    "            clear_output(True)\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            plot_history.append(np.mean(history[-100:]))\n",
    "            plt.plot(plot_history,label='loss')\n",
    "            plt.yscale('log')\n",
    "            plt.grid()\n",
    "            plt.xlabel('Шаг обучения (каждый 100й)')\n",
    "            plt.ylabel('Значение ошибки (в логарифмическом масштабе)')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество нашей модели на тестовой (или же отложенной) выборке. Для этого подсчитаем количество правильно классифицированных цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество распознавания достаточно неплохое. Протестируем на \"рукописном\" (с помощью мыши/тачпада) вводе.\n",
    "\n",
    "__Внимание! Следующая часть кода с ручной проверкой модели полезна только для демонстрации. Она не работает в JupyterLab на Google Cloud Platform ввиду ограничений со стороны JupyterLab. Если вы выполняете домашее задание и дошли до этого момента, можете переходить к выводам.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JNCleE3CJ7o",
    "outputId": "5130f6aa-7c80-43c4-d4a0-d9cd3e076eb7"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "data = None\n",
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M87eW9liCJ7p"
   },
   "outputs": [],
   "source": [
    "prepared_data = np.array(data).reshape((28, 28)).astype(np.float32)\n",
    "\n",
    "# If it fails, just comment the code below\n",
    "import scipy.ndimage as ndimage\n",
    "prepared_data = ndimage.gaussian_filter(prepared_data, sigma=(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozggh3trCJ7q",
    "outputId": "d4015144-0f6b-4718-b337-39afb4dbda3d"
   },
   "outputs": [],
   "source": [
    "plt.imshow(prepared_data.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image = torch.FloatTensor(prepared_data.reshape(1, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже можно увидеть вероятности, с которыми модель относит данное изображение к различным классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(10), F.softmax(model(transformed_image), dim=-1).detach().numpy()[0])\n",
    "plt.grid()\n",
    "_ = plt.xticks(range(10))\n",
    "plt.xlabel('predicted class label')\n",
    "plt.ylabel('class probability')\n",
    "_ = plt.title('Model confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtvXyAQzCJ7s",
    "outputId": "0af63de5-fbaf-4e96-9f0b-abb24599c9b4"
   },
   "outputs": [],
   "source": [
    "print(\"This model predicted your input as\", model(transformed_image).argmax().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ontuu1VbCJ7t"
   },
   "source": [
    "Выглядит неплохо. Для получения хороших результатов можно использовать модель с несколькими слоями (лучше сверточными).\n",
    "\n",
    "\n",
    "\n",
    "В целом, добро пожаловать в мир Искусственного Интеллекта.\n",
    "\n",
    "Данный пример был достаточно простым, на датасете MNIST не слишком сложно достичь и 100% доли правильных ответов на отложенной выборке.\n",
    "\n",
    "Если Вы хотите попрактиковаться с более сложным датасетом, Вы можете воспользоваться \n",
    "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Этот датасет полностью аналогичнен MNIST по структуре (и весь код, который использовался для MNIST может быть использован и для FashionMNIST), но в нем представлены изображения различных предметов одежды (кроссовки, футбоки и т.д.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "* Использование общепринятых терминов делает процесс построения моделей машинного обучения значительно более интуитивным. Также это значительно упрощает диалог со специалистами в области ИИ.\n",
    "* Для эффективного решения задач стоит ответить на следующие вопросы:\n",
    "    * С данными какой природы предстоит работать?\n",
    "    * Как будет измеряться качество?\n",
    "    * Какую модель/семейство моделей стоит использовать в подобных задачах?\n",
    "    * Обучающая выборка каких объемов доступна (или необходима)?\n",
    "* Разобранные примеры описывают основные шаги построения и настройки (обучения) модели. В реальных проектах возникает множество дополнительных задач (например, сбор данных или распределенное обучение моделей), но общая процедура сохраняется."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day5_Intro_to_DL_with_keras__solved.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Py3 Research",
   "language": "python",
   "name": "py3_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
